# TRM Training: Speed vs Quality Trade-offs

## Quick Decision Guide

**Want best quality?** â†’ Use Extreme preset
**Want best speed?** â†’ Use Aggressive preset with batch_size=2, compile=True
**Want balanced?** â†’ Use Aggressive preset (default)

---

## Option 1: SPEED OPTIMIZED (Default - test_local.sh)

### Configuration
```bash
./scripts/test_local.sh
```

**Settings:**
- Preset: Aggressive (supervision_weight_base=5.0, improvement_reward_scale=1.0)
- Learning rates: matrix_lr=0.001, embedding_lr=0.01
- Batch size: 2
- Compile: True
- Iterations: 200

**Performance:**
- â±ï¸ Time: ~20-25 minutes for 200 steps
- ğŸš€ Speed: ~6-8 sec/step
- ğŸ¯ Refinement: 15-25%
- ğŸ’¾ Memory: ~23-24 GB
- â­ Stability: â­â­â­â­

**Best for:** Production training, fast iteration, balanced quality

---

## Option 2: QUALITY OPTIMIZED (test_local_extreme.sh)

### Configuration
```bash
# 1. First, edit nanochat/gpt.py line 44-45:
supervision_weight_base: float = 10.0  # Change from 5.0
improvement_reward_scale: float = 2.0  # Change from 1.0

# 2. Then run:
./scripts/test_local_extreme.sh
```

**Settings:**
- Preset: Extreme (supervision_weight_base=10.0, improvement_reward_scale=2.0)
- Learning rates: matrix_lr=0.0005, embedding_lr=0.005
- Batch size: 1
- Compile: False
- Iterations: 500

**Performance:**
- â±ï¸ Time: ~2-3 hours for 500 steps
- ğŸŒ Speed: ~15-20 sec/step
- ğŸ¯ Refinement: 50-97%
- ğŸ’¾ Memory: ~20-21 GB
- â­ Stability: â­â­â­

**Best for:** Research, maximum quality experiments, final production model

---

## Option 3: BALANCED (Moderate preset)

### Configuration
```bash
# Edit nanochat/gpt.py line 44-45:
supervision_weight_base: float = 3.0
improvement_reward_scale: float = 0.5

# Then use test_local.sh with adjusted LRs:
--matrix_lr=0.002
--embedding_lr=0.02
```

**Performance:**
- â±ï¸ Time: ~15-20 minutes for 200 steps
- ğŸš€ Speed: ~5-6 sec/step
- ğŸ¯ Refinement: 8-12%
- ğŸ’¾ Memory: ~23-24 GB
- â­ Stability: â­â­â­â­â­

**Best for:** Very stable training, conservative approach

---

## Detailed Comparison Table

| Metric | Moderate | Aggressive (Default) | Extreme |
|--------|----------|---------------------|---------|
| **Refinement** | 8-12% | 15-25% | 50-97% |
| **Speed (sec/step)** | 5-6 | 6-8 | 15-20 |
| **200 steps time** | 15-20 min | 20-25 min | 60-70 min |
| **500 steps time** | 40-50 min | 50-60 min | 2-3 hrs |
| **Matrix LR** | 0.002 | 0.001 | 0.0005 |
| **Embedding LR** | 0.02 | 0.01 | 0.005 |
| **Batch size** | 2 | 2 | 1 |
| **Compile** | True | True | False |
| **Memory** | ~24 GB | ~24 GB | ~21 GB |
| **Stability** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **Gradient norms** | 0.3-0.8 | 0.5-1.5 | 2-15 |

---

## What Does Refinement Mean?

### Aggressive (15-25% refinement):
```
Step 0: Loss = 4.50  (initial answer)
Step 1: Loss = 4.20  (7% better)
Step 2: Loss = 4.05  (11% better total)
Step 3: Loss = 3.90  (13% better total) âœ…
```

### Extreme (50-97% refinement):
```
Step 0: Loss = 10.00  (rough draft - intentionally poor)
Step 1: Loss = 3.00   (70% better!) ğŸ”¥
Step 2: Loss = 0.85   (92% better total) ğŸ”¥
Step 3: Loss = 0.27   (97% better total!) ğŸ”¥ğŸ”¥ğŸ”¥
```

**The extreme model learns to:**
1. Start with a very rough answer (step 0)
2. Make dramatic improvements in each refinement pass
3. Converge to a highly polished final answer (step 3)

---

## Migration Path: Speed â†’ Quality

### Phase 1: Fast Iteration (Aggressive)
```bash
# Use while developing/experimenting
./scripts/test_local.sh
# 200 steps in ~20-25 minutes
# 15-25% refinement
```

### Phase 2: Quality Push (Extreme)
```bash
# Once you're happy with architecture, push for max quality
# Edit gpt.py to extreme preset
./scripts/test_local_extreme.sh
# 500 steps in ~2-3 hours
# 50-97% refinement
```

---

## When to Use Each Preset

### Use MODERATE when:
- âœ… You need rock-solid stability
- âœ… You're training on unfamiliar data
- âœ… You want the safest option
- âœ… Speed is important but some refinement desired

### Use AGGRESSIVE when:
- âœ… You want balanced speed/quality (RECOMMENDED)
- âœ… Production training
- âœ… Fast iteration during development
- âœ… Good refinement (15-25%) is sufficient

### Use EXTREME when:
- âœ… Final production model training
- âœ… Research experiments on refinement
- âœ… You want maximum possible quality
- âœ… You have time for longer training (2-3 hrs)
- âœ… You want dramatic progressive refinement behavior

---

## Real-World Recommendations

### For a typical project:
1. **Start with Aggressive** (`./scripts/test_local.sh`)
   - Train for 200-500 steps to validate architecture
   - ~20-60 minutes
   - 15-25% refinement is very good

2. **If results are promising, switch to Extreme**
   - Edit `gpt.py` to extreme preset
   - Train for 500-1000 steps for final model
   - ~2-6 hours
   - 50-97% refinement for maximum quality

3. **Use Moderate only if:**
   - Aggressive is unstable (shouldn't happen with proper grad clipping)
   - You need absolute maximum stability

---

## Quick Reference Commands

### Speed-optimized (default):
```bash
./scripts/test_local.sh
# No changes needed, just run!
```

### Quality-optimized:
```bash
# 1. Edit nanochat/gpt.py lines 44-45
supervision_weight_base: float = 10.0
improvement_reward_scale: float = 2.0

# 2. Run extreme training
./scripts/test_local_extreme.sh
```

### Custom tuning:
```bash
# Edit gpt.py to your preferred values:
supervision_weight_base: float = 7.0   # Between aggressive and extreme
improvement_reward_scale: float = 1.5  # Between aggressive and extreme

# Adjust LRs proportionally
# Rule of thumb: LR âˆ 1 / weight_base
# base=5 â†’ lr=0.001
# base=7 â†’ lr=0.0007
# base=10 â†’ lr=0.0005
```

---

## Bottom Line

**For most users:** Use **Aggressive preset** (default in `test_local.sh`)
- Fast, stable, good refinement (15-25%)
- Best balance of speed and quality

**For maximum quality:** Use **Extreme preset** (`test_local_extreme.sh`)
- Slower, but dramatic refinement (50-97%)
- Worth it for final production models

**Your RTX 3090 can handle both!** ğŸš€
